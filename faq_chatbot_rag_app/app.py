import streamlit as st
from rag import vector_retriever_create, ai_faq_rag



st.title("ğŸ“¦ ì£¼ë¬¸/ë°°ì†¡ FAQ ì±—ë´‡")

# ë©”ì‹œì§€ ê¸°ë¡ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì´ì „ ëŒ€í™” ì¶œë ¥
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ë°˜í’ˆì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?)")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # AI ì‘ë‹µ ì²˜ë¦¬
    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            retriever = vector_retriever_create()
            response_gen = ai_faq_rag(user_input, retriever)

            full_response = ""
            placeholder = st.empty()

            for chunk in response_gen:
                full_response += chunk
                placeholder.markdown(full_response)

            st.session_state.messages.append({
                "role": "assistant",
                "content": full_response
            })


else:
    st.warning('ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.')

